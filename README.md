# Gemini LLM Q & A Demo

<b>This is a Streamlit application demonstrating the use of the Gemini LLM (Large Language Model) for generating responses based on user input and uploaded images.</b>

![2024-02-23 16_35_44-](https://github.com/Kili66/Gemini-LLM-Application_Image_question/assets/66678981/a7bfe2fd-773e-4f7e-8365-315a7c517174)
### Prerequisites
* Make sure you have the required dependencies installed. You can install them using the following command:
  * pip install -r requirements.txt
1. Configuration
<b>Clone the repository:</b>
  * git clone https://github.com/kili66/your-repo.git
  * cd your-repo
2. Create a virtual environment:https://github.com/Kili66/Gemini-LLM-Application_Image_question
  * python -m venv venv
   1. Activate the virtual environment:
      source venv/bin/activate
2. Running the Application
* Run the Streamlit application with the following command:
* streamlit run app.py
